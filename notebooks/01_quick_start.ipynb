{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# NLP Sentiment Analysis - Quick Start Guide\n",
    "\n",
    "**Author:** Gabriel Demetrios Lafis\n",
    "\n",
    "This notebook demonstrates how to use the sentiment analysis pipeline with transformer models."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 1. Setup and Imports"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import sys\n",
    "sys.path.append('..')\n",
    "\n",
    "from src.models.sentiment_analyzer import SentimentAnalyzer, BaselineSentimentAnalyzer\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "\n",
    "# Set style\n",
    "sns.set_style('whitegrid')\n",
    "plt.rcParams['figure.figsize'] = (12, 6)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 2. Initialize Models"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Initialize transformer-based analyzer\n",
    "analyzer = SentimentAnalyzer(model_name='distilbert-base-uncased-finetuned-sst-2-english')\n",
    "\n",
    "# Initialize baseline VADER analyzer\n",
    "baseline = BaselineSentimentAnalyzer()\n",
    "\n",
    "print(f\"Transformer Model: {analyzer.model_name}\")\n",
    "print(f\"Device: {analyzer.device}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 3. Single Text Analysis"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Example text\n",
    "text = \"This product exceeded all my expectations! The quality is outstanding and delivery was fast.\"\n",
    "\n",
    "# Analyze with transformer model\n",
    "result = analyzer.predict(text, return_all_scores=True)\n",
    "\n",
    "print(f\"Text: {text}\\n\")\n",
    "print(f\"Sentiment: {result['sentiment']}\")\n",
    "print(f\"Confidence: {result['confidence']:.2%}\")\n",
    "print(f\"\\nAll Scores:\")\n",
    "for sentiment, score in result['scores'].items():\n",
    "    print(f\"  {sentiment}: {score:.4f}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 4. Batch Analysis"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Sample texts\n",
    "texts = [\n",
    "    \"This is the best product I've ever bought!\",\n",
    "    \"Terrible quality. Complete waste of money.\",\n",
    "    \"It's okay, nothing special.\",\n",
    "    \"Amazing customer service and fast shipping!\",\n",
    "    \"Very disappointed with this purchase.\",\n",
    "    \"Average product, meets basic expectations.\"\n",
    "]\n",
    "\n",
    "# Analyze batch\n",
    "results = analyzer.predict(texts, return_all_scores=True)\n",
    "\n",
    "# Create DataFrame\n",
    "df = pd.DataFrame([\n",
    "    {\n",
    "        'text': text,\n",
    "        'sentiment': result['sentiment'],\n",
    "        'confidence': result['confidence']\n",
    "    }\n",
    "    for text, result in zip(texts, results)\n",
    "])\n",
    "\n",
    "print(df.to_string(index=False))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 5. Model Comparison"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Compare transformer vs VADER\n",
    "test_text = \"The product is good but the delivery was slow.\"\n",
    "\n",
    "transformer_result = analyzer.predict(test_text, return_all_scores=True)\n",
    "vader_result = baseline.predict(test_text)\n",
    "\n",
    "print(f\"Text: {test_text}\\n\")\n",
    "print(f\"Transformer Model:\")\n",
    "print(f\"  Sentiment: {transformer_result['sentiment']}\")\n",
    "print(f\"  Confidence: {transformer_result['confidence']:.2%}\")\n",
    "print(f\"\\nVADER Baseline:\")\n",
    "print(f\"  Sentiment: {vader_result['sentiment']}\")\n",
    "print(f\"  Confidence: {vader_result['confidence']:.2%}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 6. Visualization"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Visualize sentiment distribution\n",
    "fig, axes = plt.subplots(1, 2, figsize=(14, 5))\n",
    "\n",
    "# Sentiment counts\n",
    "sentiment_counts = df['sentiment'].value_counts()\n",
    "axes[0].bar(sentiment_counts.index, sentiment_counts.values, color=['red', 'gray', 'green'])\n",
    "axes[0].set_title('Sentiment Distribution', fontsize=14, fontweight='bold')\n",
    "axes[0].set_xlabel('Sentiment')\n",
    "axes[0].set_ylabel('Count')\n",
    "\n",
    "# Confidence distribution\n",
    "axes[1].hist(df['confidence'], bins=10, color='skyblue', edgecolor='black')\n",
    "axes[1].set_title('Confidence Score Distribution', fontsize=14, fontweight='bold')\n",
    "axes[1].set_xlabel('Confidence')\n",
    "axes[1].set_ylabel('Frequency')\n",
    "\n",
    "plt.tight_layout()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 7. Prediction Explanation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Get explanation for a prediction\n",
    "text_to_explain = \"This product is absolutely fantastic and exceeded my expectations!\"\n",
    "\n",
    "explanation = analyzer.explain_prediction(text_to_explain)\n",
    "\n",
    "print(f\"Text: {text_to_explain}\\n\")\n",
    "print(f\"Predicted Sentiment: {explanation['sentiment']}\")\n",
    "print(f\"Confidence: {explanation['confidence']:.2%}\\n\")\n",
    "\n",
    "if 'top_tokens' in explanation:\n",
    "    print(\"Most Important Tokens:\")\n",
    "    for i, token_info in enumerate(explanation['top_tokens'][:5], 1):\n",
    "        print(f\"  {i}. '{token_info['token']}' - Importance: {token_info['importance']:.4f}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 8. Performance Benchmarking"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import time\n",
    "\n",
    "# Benchmark inference time\n",
    "test_texts = [\"This is a test sentence.\"] * 100\n",
    "\n",
    "# Transformer model\n",
    "start = time.time()\n",
    "_ = analyzer.batch_predict(test_texts, batch_size=32, show_progress=False)\n",
    "transformer_time = time.time() - start\n",
    "\n",
    "# VADER baseline\n",
    "start = time.time()\n",
    "_ = baseline.predict(test_texts)\n",
    "vader_time = time.time() - start\n",
    "\n",
    "print(f\"Processing 100 texts:\")\n",
    "print(f\"  Transformer: {transformer_time:.3f}s ({transformer_time/100*1000:.2f}ms per text)\")\n",
    "print(f\"  VADER: {vader_time:.3f}s ({vader_time/100*1000:.2f}ms per text)\")\n",
    "print(f\"  Speedup: {transformer_time/vader_time:.2f}x slower\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Conclusion\n",
    "\n",
    "This notebook demonstrated:\n",
    "- Single and batch sentiment analysis\n",
    "- Model comparison (Transformer vs VADER)\n",
    "- Visualization of results\n",
    "- Prediction explanation\n",
    "- Performance benchmarking\n",
    "\n",
    "The transformer-based models provide higher accuracy at the cost of increased inference time compared to traditional methods like VADER."
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
